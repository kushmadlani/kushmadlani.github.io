---
title: 'A Simple EDA of the arXiV dataset'
date: 25-09-2020
classes: wide
---

In this post we're going to perform a straightforward Exploratory Data Analysis (EDA) on a dataset; whereby we load it, perform some sensible preprocessing steps, generate some statistics to get a sense of the data then answer some more interesting questions about the dataset with some plots.

The dataset we're going to examine is the [ArXiv dataset](https://www.kaggle.com/Cornell-University/arxiv) from Kaggle, a "repository of 1.7 million articles, with relevant features such as article titles, authors, categories, abstracts, full text PDFs, and more."

ArXiv provides open access to scholarly articles (such as research papers), so we can do some interesting analysis about the change in interest of, say, AI/ML related articles.

## Creating a DataFrame

```python
import numpy as np 
import pandas as pd
import plotly_express as px
import os
import json
pd.set_option('float_format', '{:f}'.format)
```
Let's load the data, we use 'yield' to get the necessary information in a loop since json files in the dataset are huge so we avoid memory problems.

```python
file_path = 'arxiv-metadata-oai-snapshot.json'

def get_metadata():
    with open(file_path, 'r') as f:
        for line in f:
            yield line
```
Looking at one example of a paper we see lots of information available: a series of dates in the 'versions', author names, an abstract, categories and so on.

```python
metadata = get_metadata()
for paper in metadata:
    for k, v in json.loads(paper).items():
        print(f'{k}: {v}')
    break
```
    id: 0704.0001
    submitter: Pavel Nadolsky
    authors: C. Bal\'azs, E. L. Berger, P. M. Nadolsky, C.-P. Yuan
    title: Calculation of prompt diphoton production cross sections at Tevatron and
      LHC energies
    comments: 37 pages, 15 figures; published version
    journal-ref: Phys.Rev.D76:013009,2007
    doi: 10.1103/PhysRevD.76.013009
    report-no: ANL-HEP-PR-07-12
    categories: hep-ph
    license: None
    abstract:   A fully differential calculation in perturbative quantum chromodynamics is
    presented for the production of massive photon pairs at hadron colliders. All
    next-to-leading order perturbative contributions from quark-antiquark,
    gluon-(anti)quark, and gluon-gluon subprocesses are included, as well as
    all-orders resummation of initial-state gluon radiation valid at
    next-to-next-to-leading logarithmic accuracy. The region of phase space is
    specified in which the calculation is most reliable. Good agreement is
    demonstrated with data from the Fermilab Tevatron, and predictions are made for
    more detailed tests with CDF and DO data. Predictions are shown for
    distributions of diphoton pairs produced at the energy of the Large Hadron
    Collider (LHC). Distributions of the diphoton pairs from the decay of a Higgs
    boson are contrasted with those produced from QCD processes at the LHC, showing
    that enhanced sensitivity to the signal can be obtained with judicious
    selection of events.
    
    versions: [{'version': 'v1', 'created': 'Mon, 2 Apr 2007 19:18:42 GMT'}, {'version': 'v2', 'created': 'Tue, 24 Jul 2007 20:10:27 GMT'}]
    update_date: 2008-11-26
    authors_parsed: [['Balázs', 'C.', ''], ['Berger', 'E. L.', ''], ['Nadolsky', 'P. M.', ''], ['Yuan', 'C. -P.', '']]


We now extract a subset of the fields which we will perform our anlysis on.

```python
titles, abstracts, versions, categories, doi, authors_parsed = [], [], [], [], [], []

metadata = get_metadata()
# loop over all papers
for paper in metadata:
    # extract single paper
    paper_dict = json.loads(paper)
    version = paper_dict.get('versions')
    try:
        versions.append(version[-1]['created']) # choose created as the most recent version
        titles.append(paper_dict.get('title'))
        abstracts.append(paper_dict.get('abstract'))
        categories.append(paper_dict.get('categories'))
        doi.append(paper_dict.get('doi'))
        authors_parsed.append(paper_dict.get('authors_parsed'))
    except:
        pass
```
Let's create a `pandas` dataframe to make our analysis easier:

```python
papers = pd.DataFrame({
    'title': titles,
    'abstract': abstracts,
    'categories': categories,
    'version': versions,
    'doi': doi,
    'authors': authors_parsed
})
papers.head()

# reduce memory constraints
del titles, abstracts, versions, categories, doi, authors_parsed
```

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>title</th>
      <th>abstract</th>
      <th>categories</th>
      <th>version</th>
      <th>doi</th>
      <th>authors</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Calculation of prompt diphoton production cros...</td>
      <td>A fully differential calculation in perturba...</td>
      <td>hep-ph</td>
      <td>Tue, 24 Jul 2007 20:10:27 GMT</td>
      <td>10.1103/PhysRevD.76.013009</td>
      <td>[[Balázs, C., ], [Berger, E. L., ], [Nadolsky,...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Sparsity-certifying Graph Decompositions</td>
      <td>We describe a new algorithm, the $(k,\ell)$-...</td>
      <td>math.CO cs.CG</td>
      <td>Sat, 13 Dec 2008 17:26:00 GMT</td>
      <td>None</td>
      <td>[[Streinu, Ileana, ], [Theran, Louis, ]]</td>
    </tr>
    <tr>
      <th>2</th>
      <td>The evolution of the Earth-Moon system based o...</td>
      <td>The evolution of Earth-Moon system is descri...</td>
      <td>physics.gen-ph</td>
      <td>Sun, 13 Jan 2008 00:36:28 GMT</td>
      <td>None</td>
      <td>[[Pan, Hongjun, ]]</td>
    </tr>
    <tr>
      <th>3</th>
      <td>A determinant of Stirling cycle numbers counts...</td>
      <td>We show that a determinant of Stirling cycle...</td>
      <td>math.CO</td>
      <td>Sat, 31 Mar 2007 03:16:14 GMT</td>
      <td>None</td>
      <td>[[Callan, David, ]]</td>
    </tr>
    <tr>
      <th>4</th>
      <td>From dyadic $\Lambda_{\alpha}$ to $\Lambda_{\a...</td>
      <td>In this paper we show how to compute the $\L...</td>
      <td>math.CA math.FA</td>
      <td>Mon, 2 Apr 2007 18:09:58 GMT</td>
      <td>None</td>
      <td>[[Abu-Shammala, Wael, ], [Torchinsky, Alberto, ]]</td>
    </tr>
  </tbody>
</table>
</div>


## Preprocessing

As we can see, some columns have different data types, whilst we also have some None or missing values present. The `isna()` function is helpful to find None or NaN values in data. As an example lets see how many of our papers do not have a DOI:


```python
print('{} of {} papers without DOI'.format(papers['doi'].isna().sum(), len(papers)))
```
    846236 of 1765688 papers without DOI

Now since DOI is often added after a paper is published ([source](https://academia.stackexchange.com/questions/62480/why-does-arxiv-org-not-assign-dois)) we won't remove this column but if we wanted to something such as `papers[papers.doi.notnull()]` would do the trick.

Next let's clean up some of the columns: 
- We want the *abstract* to be one continous string of text without new lines. 
- *versions* need to be Python datetime objects then lets extract the month and year they were published.
- The *authors* column would be better as a list of strings

```python
# clean abstracts
papers['abstract'] = papers['abstract'].apply(lambda x: x.replace("\n",""))
papers['abstract'] = papers['abstract'].apply(lambda x: x.strip())

# extract date time info 
papers['DateTime']= pd.to_datetime(papers['version'])
papers['month'] = pd.DatetimeIndex(papers['DateTime']).month
papers['year'] = pd.DatetimeIndex(papers['DateTime']).year

# clean authors
papers['authors']= papers['authors'].apply(lambda authors:[(" ".join(a)).strip() for a in authors])
papers.head()
```
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>title</th>
      <th>abstract</th>
      <th>categories</th>
      <th>version</th>
      <th>doi</th>
      <th>authors</th>
      <th>DateTime</th>
      <th>month</th>
      <th>year</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Calculation of prompt diphoton production cros...</td>
      <td>A fully differential calculation in perturbati...</td>
      <td>hep-ph</td>
      <td>Tue, 24 Jul 2007 20:10:27 GMT</td>
      <td>10.1103/PhysRevD.76.013009</td>
      <td>[Balázs C., Berger E. L., Nadolsky P. M., Yuan...</td>
      <td>2007-07-24 20:10:27+00:00</td>
      <td>7</td>
      <td>2007</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Sparsity-certifying Graph Decompositions</td>
      <td>We describe a new algorithm, the $(k,\ell)$-pe...</td>
      <td>math.CO cs.CG</td>
      <td>Sat, 13 Dec 2008 17:26:00 GMT</td>
      <td>None</td>
      <td>[Streinu Ileana, Theran Louis]</td>
      <td>2008-12-13 17:26:00+00:00</td>
      <td>12</td>
      <td>2008</td>
    </tr>
    <tr>
      <th>2</th>
      <td>The evolution of the Earth-Moon system based o...</td>
      <td>The evolution of Earth-Moon system is describe...</td>
      <td>physics.gen-ph</td>
      <td>Sun, 13 Jan 2008 00:36:28 GMT</td>
      <td>None</td>
      <td>[Pan Hongjun]</td>
      <td>2008-01-13 00:36:28+00:00</td>
      <td>1</td>
      <td>2008</td>
    </tr>
    <tr>
      <th>3</th>
      <td>A determinant of Stirling cycle numbers counts...</td>
      <td>We show that a determinant of Stirling cycle n...</td>
      <td>math.CO</td>
      <td>Sat, 31 Mar 2007 03:16:14 GMT</td>
      <td>None</td>
      <td>[Callan David]</td>
      <td>2007-03-31 03:16:14+00:00</td>
      <td>3</td>
      <td>2007</td>
    </tr>
    <tr>
      <th>4</th>
      <td>From dyadic $\Lambda_{\alpha}$ to $\Lambda_{\a...</td>
      <td>In this paper we show how to compute the $\Lam...</td>
      <td>math.CA math.FA</td>
      <td>Mon, 2 Apr 2007 18:09:58 GMT</td>
      <td>None</td>
      <td>[Abu-Shammala Wael, Torchinsky Alberto]</td>
      <td>2007-04-02 18:09:58+00:00</td>
      <td>4</td>
      <td>2007</td>
    </tr>
  </tbody>
</table>
</div>

## Analysis

Looking at each paper, we might want to know things such as how many categories does each paper have? How many words is in the abstract? How many authors are in this paper? Pandas makes this easy with the `apply` method where you can apply an arbitrary function to produce a new column from another, as below.


```python
papers['num_categories'] = papers['categories'].apply(lambda x:len(x)).astype('int')
papers['num_words_abstract'] = papers['abstract'].apply(lambda x:len(x.split())).astype('int')
papers['num_authors'] = papers['authors'].apply(lambda x:len(x)).astype('int')
papers.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>title</th>
      <th>abstract</th>
      <th>categories</th>
      <th>version</th>
      <th>doi</th>
      <th>authors</th>
      <th>DateTime</th>
      <th>month</th>
      <th>year</th>
      <th>num_categories</th>
      <th>num_words_abstract</th>
      <th>num_authors</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Calculation of prompt diphoton production cros...</td>
      <td>A fully differential calculation in perturbati...</td>
      <td>hep-ph</td>
      <td>Tue, 24 Jul 2007 20:10:27 GMT</td>
      <td>10.1103/PhysRevD.76.013009</td>
      <td>[Balázs C., Berger E. L., Nadolsky P. M., Yuan...</td>
      <td>2007-07-24 20:10:27+00:00</td>
      <td>7</td>
      <td>2007</td>
      <td>6</td>
      <td>127</td>
      <td>4</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Sparsity-certifying Graph Decompositions</td>
      <td>We describe a new algorithm, the $(k,\ell)$-pe...</td>
      <td>math.CO cs.CG</td>
      <td>Sat, 13 Dec 2008 17:26:00 GMT</td>
      <td>None</td>
      <td>[Streinu Ileana, Theran Louis]</td>
      <td>2008-12-13 17:26:00+00:00</td>
      <td>12</td>
      <td>2008</td>
      <td>13</td>
      <td>105</td>
      <td>2</td>
    </tr>
    <tr>
      <th>2</th>
      <td>The evolution of the Earth-Moon system based o...</td>
      <td>The evolution of Earth-Moon system is describe...</td>
      <td>physics.gen-ph</td>
      <td>Sun, 13 Jan 2008 00:36:28 GMT</td>
      <td>None</td>
      <td>[Pan Hongjun]</td>
      <td>2008-01-13 00:36:28+00:00</td>
      <td>1</td>
      <td>2008</td>
      <td>14</td>
      <td>133</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>A determinant of Stirling cycle numbers counts...</td>
      <td>We show that a determinant of Stirling cycle n...</td>
      <td>math.CO</td>
      <td>Sat, 31 Mar 2007 03:16:14 GMT</td>
      <td>None</td>
      <td>[Callan David]</td>
      <td>2007-03-31 03:16:14+00:00</td>
      <td>3</td>
      <td>2007</td>
      <td>7</td>
      <td>32</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>From dyadic $\Lambda_{\alpha}$ to $\Lambda_{\a...</td>
      <td>In this paper we show how to compute the $\Lam...</td>
      <td>math.CA math.FA</td>
      <td>Mon, 2 Apr 2007 18:09:58 GMT</td>
      <td>None</td>
      <td>[Abu-Shammala Wael, Torchinsky Alberto]</td>
      <td>2007-04-02 18:09:58+00:00</td>
      <td>4</td>
      <td>2007</td>
      <td>15</td>
      <td>35</td>
      <td>2</td>
    </tr>
  </tbody>
</table>
</div>



We're now ready to ask some questions about the data, each which can be answered in a few lines of code:

__1. How many authors to papers have?__

Here we use the `describe()` method to get a high level summary of the column in question, where a histogram isn't necessary at this point. We see that most papers have 4 authors or less but there's a heavy right tail with some papers having a few thousand others. Odd. 


```python
papers['num_authors'].astype('int').describe()
```

    count   1765688.000000
    mean          4.153911
    std          20.305943
    min           1.000000
    25%           2.000000
    50%           3.000000
    75%           4.000000
    max        2832.000000
    Name: num_authors, dtype: float64

Let's look into the heavy tail a bit more - we see that the top 3 papers with most authors are in the 'hep-ex' cateogory which stands for 'High Energy Physics - Experiment'. If we read the abstract of the most authored paper we see in fact its the result from an experiment Large Hadron Collider at CERN, the product of worldwide scientific collaboratin (and so making sense of the 2832 authors!)

```python
papers.sort_values(by='num_authors', ascending=False).head()
```
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>title</th>
      <th>abstract</th>
      <th>categories</th>
      <th>version</th>
      <th>doi</th>
      <th>authors</th>
      <th>DateTime</th>
      <th>month</th>
      <th>year</th>
      <th>num_categories</th>
      <th>num_words_abstract</th>
      <th>num_authors</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>574385</th>
      <td>Observation of the rare $B^0_s\to\mu^+\mu^-$ d...</td>
      <td>A joint measurement is presented of the branch...</td>
      <td>hep-ex hep-ph</td>
      <td>Mon, 17 Aug 2015 15:53:53 GMT</td>
      <td>10.1038/nature14474</td>
      <td>[CMS The, Collaborations LHCb, :, Khachatryan ...</td>
      <td>2015-08-17 15:53:53+00:00</td>
      <td>8</td>
      <td>2015</td>
      <td>13</td>
      <td>99</td>
      <td>2832</td>
    </tr>
    <tr>
      <th>101754</th>
      <td>Expected Performance of the ATLAS Experiment -...</td>
      <td>A detailed study is presented of the expected ...</td>
      <td>hep-ex</td>
      <td>Fri, 14 Aug 2009 13:50:42 GMT</td>
      <td>None</td>
      <td>[The ATLAS Collaboration, Aad G., Abat E., Abb...</td>
      <td>2009-08-14 13:50:42+00:00</td>
      <td>8</td>
      <td>2009</td>
      <td>6</td>
      <td>80</td>
      <td>2612</td>
    </tr>
    <tr>
      <th>535194</th>
      <td>The Physics of the B Factories</td>
      <td>This work is on the Physics of the B Factories...</td>
      <td>hep-ex hep-ph</td>
      <td>Sat, 31 Oct 2015 06:42:11 GMT</td>
      <td>10.1140/epjc/s10052-014-3026-9</td>
      <td>[Bevan A. J., Golob B., Mannel Th., Prell S., ...</td>
      <td>2015-10-31 06:42:11+00:00</td>
      <td>10</td>
      <td>2015</td>
      <td>13</td>
      <td>111</td>
      <td>2034</td>
    </tr>
    <tr>
      <th>901222</th>
      <td>Search for High-energy Neutrinos from Binary N...</td>
      <td>The Advanced LIGO and Advanced Virgo observato...</td>
      <td>astro-ph.HE</td>
      <td>Thu, 9 Nov 2017 05:44:40 GMT</td>
      <td>10.3847/2041-8213/aa9aed</td>
      <td>[Albert A.  ANTARES, IceCube, Pierre\n  Auger,...</td>
      <td>2017-11-09 05:44:40+00:00</td>
      <td>11</td>
      <td>2017</td>
      <td>11</td>
      <td>170</td>
      <td>1945</td>
    </tr>
    <tr>
      <th>1041880</th>
      <td>Search for Multi-messenger Sources of Gravitat...</td>
      <td>Astrophysical sources of gravitational waves, ...</td>
      <td>astro-ph.HE</td>
      <td>Thu, 15 Nov 2018 21:37:04 GMT</td>
      <td>10.3847/1538-4357/aaf21d</td>
      <td>[ANTARES, IceCube, LIGO, Collaborations Virgo,...</td>
      <td>2018-11-15 21:37:04+00:00</td>
      <td>11</td>
      <td>2018</td>
      <td>11</td>
      <td>133</td>
      <td>1595</td>
    </tr>
  </tbody>
</table>
</div>


```python
papers.iloc[574385]['abstract'][:250]
```
    'A joint measurement is presented of the branching fractions$B^0_s\\to\\mu^+\\mu^-$ and $B^0\\to\\mu^+\\mu^-$ in proton-proton collisions at theLHC by the CMS and LHCb experiments. The data samples were collected in 2011 ata centre-of-mass energy of 7 TeV, '


__2. How many words does the average abstract have?__

Next lets look at how abstracts are in general, where a histogram will be a good option to visualise the data. As expected most aren't too long with the average abstract 122 words long.


```python
fig = px.histogram(papers, x="num_words_abstract", nbins=500)
fig.show()
```
![](/images/arxiv_eda/plot1.png)

__3. How many papers have been produced over time?__

We plot a line chart to answer this question. To count the number of papers per year, we used the `groupby()` method, a powerful tool in `pandas` to aggregate information in a large variety of ways.

There's a steady growth of papers published over time as ArXiV became more popular and wide reaching, whilst also perhaps reflecting the higher output of research in Science across the world. Since we're half way through 2020 the line tails off as expected. This makes sense.

```python
papers_per_year = papers.groupby(['year']).size().reset_index().rename(columns={0:'n_papers'})
fig = px.line(x='year', y='n_papers', data_frame=papers_per_year)
fig.show()
```
![](/images/arxiv_eda/plot2.png)

__4. In which months are the most papers published?__

We see little variation across months excpet a slight decrease across Winter and Christmas months, but nothing significant.


```python
papers_per_month = papers.groupby(['month']).size().reset_index().rename(columns={0:'n_papers'})
fig = px.bar(x='month', y='n_papers', data_frame=papers_per_month)
fig.show()
```
![](/images/arxiv_eda/plot3.png)

## AI & ML

Now let's filter for papers related to AI & ML. It's not as simple as using `papers['categories'].isin(ai_list)` since most papers have more than one categories. So we use the intermediate step of seeing if any of the categories of the paper are in the first. If at least one is in the list we assign a value of `True` to this intermediate variable and filter for values. Note this could have been done in a single line but for clarity we split this out.


```python
ai_list=['cs.AI','cs.LG','stat.ML']
papers['is_ai'] = papers['categories'].apply((lambda x: any(ele in x for ele in ai_list)==True))
ai_papers = papers[papers['is_ai']==True]
ai_papers.head()
```

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>title</th>
      <th>abstract</th>
      <th>categories</th>
      <th>version</th>
      <th>doi</th>
      <th>authors</th>
      <th>DateTime</th>
      <th>month</th>
      <th>year</th>
      <th>num_categories</th>
      <th>num_words_abstract</th>
      <th>num_authors</th>
      <th>is_ai</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>46</th>
      <td>Intelligent location of simultaneously active ...</td>
      <td>The intelligent acoustic emission locator is d...</td>
      <td>cs.NE cs.AI</td>
      <td>Sun, 1 Apr 2007 13:06:50 GMT</td>
      <td>None</td>
      <td>[Kosel T., Grabec I.]</td>
      <td>2007-04-01 13:06:50+00:00</td>
      <td>4</td>
      <td>2007</td>
      <td>11</td>
      <td>155</td>
      <td>2</td>
      <td>True</td>
    </tr>
    <tr>
      <th>49</th>
      <td>Intelligent location of simultaneously active ...</td>
      <td>Part I describes an intelligent acoustic emiss...</td>
      <td>cs.NE cs.AI</td>
      <td>Sun, 1 Apr 2007 18:53:13 GMT</td>
      <td>None</td>
      <td>[Kosel T., Grabec I.]</td>
      <td>2007-04-01 18:53:13+00:00</td>
      <td>4</td>
      <td>2007</td>
      <td>11</td>
      <td>124</td>
      <td>2</td>
      <td>True</td>
    </tr>
    <tr>
      <th>303</th>
      <td>The World as Evolving Information</td>
      <td>This paper discusses the benefits of describin...</td>
      <td>cs.IT cs.AI math.IT q-bio.PE</td>
      <td>Wed, 13 Oct 2010 19:49:16 GMT</td>
      <td>10.1007/978-3-642-18003-3_10</td>
      <td>[Gershenson Carlos]</td>
      <td>2010-10-13 19:49:16+00:00</td>
      <td>10</td>
      <td>2010</td>
      <td>28</td>
      <td>107</td>
      <td>1</td>
      <td>True</td>
    </tr>
    <tr>
      <th>670</th>
      <td>Learning from compressed observations</td>
      <td>The problem of statistical learning is to cons...</td>
      <td>cs.IT cs.LG math.IT</td>
      <td>Thu, 5 Apr 2007 02:57:15 GMT</td>
      <td>10.1109/ITW.2007.4313111</td>
      <td>[Raginsky Maxim]</td>
      <td>2007-04-05 02:57:15+00:00</td>
      <td>4</td>
      <td>2007</td>
      <td>19</td>
      <td>138</td>
      <td>1</td>
      <td>True</td>
    </tr>
    <tr>
      <th>953</th>
      <td>Sensor Networks with Random Links: Topology De...</td>
      <td>In a sensor network, in practice, the communic...</td>
      <td>cs.IT cs.LG math.IT</td>
      <td>Fri, 6 Apr 2007 21:58:52 GMT</td>
      <td>10.1109/TSP.2008.920143</td>
      <td>[Kar Soummya, Moura Jose M. F.]</td>
      <td>2007-04-06 21:58:52+00:00</td>
      <td>4</td>
      <td>2007</td>
      <td>19</td>
      <td>244</td>
      <td>2</td>
      <td>True</td>
    </tr>
  </tbody>
</table>
</div>

As before lets try and answer some questions about this subset of the data.

__5. What is the growth of of AI & ML papers published over the years?__

For this we need to count both the total number of papers published each year as well as the total number of AI & ML papers published each year; then we compare the two and plot the result. As before we use the `groupby()` method on the main and smaller dataframes, then use `merge()` to compare the two.

The plot shows an exponential growth in the topic kicking off around 2006, around the time ImageNet was released with several other seminal papers contributing to this explosion of growth.

```python
# total papers published per year
all_papers_per_year = papers.groupby(['year']).size().reset_index().rename(columns={0:'all'})
# AI & ML papers published per year
ai_papers_per_year = ai_papers.groupby(['year']).size().reset_index().rename(columns={0:'AI'})

# merge and calculate percentage
compare = all_papers_per_year.merge(ai_papers_per_year, how='inner')
compare['ratio'] = compare['AI']/compare['all']

# plot
fig = px.line(x='year', y='ratio', data_frame=compare)
fig.show()
```
![](/images/arxiv_eda/plot4.png)

__6. Which authors have published the most work?__

Yoshua Bengio, one of the fathers of Deep Learning, comes top of the list with over 300 papers published in our dataset! An impressive number.

```python
# flatten list of authors
authors = [y for x in ai_papers['authors'].tolist() for y in x]
authors_df = pd.DataFrame({'authors': authors}).groupby(['authors']).size().reset_index().rename(columns={0:'count'})
authors_df = authors_df.sort_values('count',ascending=False).head(15)
# plot
fig = px.bar(x='count', y='authors', data_frame=authors_df)
fig.show()
```
![](/images/arxiv_eda/plot5.png)

## Conclusion

There you have a quick intro to EDA with some useful methods in `pandas` that help you along your way. Its always important to understand your dataset before diving into a Machine Learning model and asking + answering some high level questions is a good way to start. Your data should always inform your model choices and make you think about what to try and why.
